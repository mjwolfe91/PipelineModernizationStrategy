This is the streaming implementation of the basic data pipeline class. It contains the basic components to connet to a streaming source and create a data stream to a target. There is also an infrastructure package that provides a Kubernetes cluster that will support a Kafka source and PySpark cluster to consume from it. This can be extended to create a streaming data pipeline from a specific source. The extension should include an infrastructure-as-code approach to build the Kubernetes cluster on a cloud provider (such as EKS or GKS).